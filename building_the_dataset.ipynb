{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "\n",
    "In this notebook, the dataset of world traditional music is built. Here are the steps:\n",
    "\n",
    "1. From the existing music files in the `data/audio/` directory, each file is cut into 10-second clips.\n",
    "2. The clips are saved in the `data/clips/` directory.\n",
    "3. The clips are then converted to spectrograms using the Librosa library.\n",
    "4. The spectrograms are saved in the `data/spectrograms/` directory.\n",
    "5. The metadata is saved in the `data/metadata.csv` file and contains for each original audio_file:\n",
    "    - the name of the audio file\n",
    "    - the genre\n",
    "    - the region\n",
    "    - the country\n",
    "    - the language\n",
    "    - the duration\n",
    "    - the sample rate\n",
    "    - the range (start_index, end_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convertions import mp3_to_signal, signal_to_spectro, spectro_to_image\n",
    "from convertions import image_to_spectro, spectro_to_signal, signal_to_mp3\n",
    "from convertions import signal_batch_maker, signal_batch_joiner\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_DURATION = 10 # seconds\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "metadata_columns = ['filename', 'genre', 'region', 'country', 'language', 'duration', 'sample_rate', 'index_start', 'index_end']\n",
    "\n",
    "# if the metadata file is not present, create it, else load it\n",
    "if not os.path.exists('data/metadata.csv'):\n",
    "    metadata_df = pd.DataFrame(columns=metadata_columns)\n",
    "    metadata_df.to_csv('data/metadata.csv', index=False)\n",
    "\n",
    "metadata_df = pd.read_csv('data/metadata.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Cut the audio files into 10-second clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:08<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_files = [f for f in os.listdir('data/audio') if f.endswith('.mp3')]\n",
    "\n",
    "clips = []\n",
    "current_clip_index = 0\n",
    "\n",
    "for audio_file in tqdm(audio_files):\n",
    "    signal, sample_rate = mp3_to_signal('data/audio/' + audio_file)\n",
    "    \n",
    "    audio_duration = len(signal) / sample_rate # seconds\n",
    "        \n",
    "    # create audio clips\n",
    "    new_clips = signal_batch_maker(signal, CLIP_DURATION*sample_rate)\n",
    "    for clip in new_clips:\n",
    "        clips.append(clip)\n",
    "    \n",
    "    lower_index = current_clip_index\n",
    "    current_clip_index = len(clips)\n",
    "    \n",
    "    # update metadata\n",
    "    metadata_index = len(metadata_df)\n",
    "    if metadata_df['filename'].str.contains(audio_file).any():\n",
    "        metadata_index = metadata_df[metadata_df['filename'] == audio_file].index[0]\n",
    "    metadata_df.loc[metadata_index, 'filename'] = audio_file\n",
    "    metadata_df.loc[metadata_index, 'sample_rate'] = sample_rate\n",
    "    metadata_df.loc[metadata_index, 'duration'] = audio_duration\n",
    "    metadata_df.loc[metadata_index, 'index_start'] = lower_index\n",
    "    metadata_df.loc[metadata_index, 'index_end'] = current_clip_index - 1\n",
    "    \n",
    "\n",
    "metadata_df = metadata_df.sort_values(by='index_start')\n",
    "\n",
    "metadata_df.to_csv('data/metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Save the clips in the `data/clips/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:55<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "current_index_end = -1\n",
    "\n",
    "pbar = tqdm(total=len(clips))\n",
    "\n",
    "for i, clip in enumerate(clips):\n",
    "    if i > current_index_end:\n",
    "        sub_df = metadata_df[metadata_df['index_end'] > i]\n",
    "        current_index_end = int(sub_df['index_end'].iloc[0])\n",
    "        current_sample_rate = int(sub_df['sample_rate'].iloc[0])\n",
    "    signal_to_mp3(clip, current_sample_rate, 'data/clips/' + str(i) + '.mp3')\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Convert the clips to spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/174 [00:25<?, ?it/s]\n",
      "100%|██████████| 174/174 [00:17<00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:31<00:00, 10.67it/s]"
     ]
    }
   ],
   "source": [
    "current_index_end = -1\n",
    "\n",
    "pbar = tqdm(total=len(clips))\n",
    "\n",
    "for i, clip in enumerate(clips):\n",
    "    if i > current_index_end:\n",
    "        sub_df = metadata_df[metadata_df['index_end'] > i]\n",
    "        current_index_end = int(sub_df['index_end'].iloc[0])\n",
    "        current_sample_rate = int(sub_df['sample_rate'].iloc[0])\n",
    "    spectro = signal_to_spectro(clip, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    spectro_to_image(spectro, 'data/spectrograms/' + str(i) + '.png')\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Save the spectrograms in the `data/spectrograms/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
