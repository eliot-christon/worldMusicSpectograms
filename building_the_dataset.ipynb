{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "\n",
    "In this notebook, the dataset of world traditional music is built. Here are the steps:\n",
    "\n",
    "- From the existing music files in the `data/audio/` directory, each file is cut into 10-second clips.\n",
    "- The clips are saved in the `data/clips/` directory.\n",
    "- The clips are then converted to spectrograms using the Librosa library.\n",
    "- The spectrograms are saved in the `data/spectrograms/` directory.\n",
    "- The metadata is saved in the `data/metadata.csv` file and contains for each original audio_file:\n",
    "    - the name of the audio file\n",
    "    - the genre\n",
    "    - the region\n",
    "    - the country\n",
    "    - the language of the song (if available)\n",
    "    - the duration in seconds\n",
    "    - the sample rate in Hz\n",
    "    - the index_start, first clip index for the audio file\n",
    "    - the index_end, last clip index for the audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convertions import mp3_to_signal, signal_to_spectro, spectro_to_image, spectro_to_mel_spectro, signal_to_mp3, signal_batch_maker\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_DURATION = 10 # seconds\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "metadata_columns = ['filename', 'genre', 'region', 'country', 'language', 'instruments', 'duration', 'sample_rate', 'index_start', 'index_end']\n",
    "\n",
    "# if the metadata file is not present, create it, else load it\n",
    "if not os.path.exists('data/metadata.csv'):\n",
    "    metadata_df = pd.DataFrame(columns=metadata_columns)\n",
    "    metadata_df.to_csv('data/metadata.csv', index=False)\n",
    "\n",
    "metadata_df = pd.read_csv('data/metadata.csv', header=0)\n",
    "\n",
    "clips_df = pd.DataFrame(columns=['min_spectro_db', 'max_spectro_db', 'filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Cut the audio files into 10-second clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "audio_files = [f for f in os.listdir('data/audio') if f.endswith('.mp3')]\n",
    "\n",
    "clips = []\n",
    "current_clip_index = 0\n",
    "\n",
    "for audio_file in tqdm(audio_files):\n",
    "    signal, sample_rate = mp3_to_signal('data/audio/' + audio_file)\n",
    "    \n",
    "    audio_duration = len(signal) / sample_rate # seconds\n",
    "        \n",
    "    # create audio clips\n",
    "    new_clips = signal_batch_maker(signal, CLIP_DURATION*sample_rate)\n",
    "    for clip in new_clips:\n",
    "        clips.append(clip)\n",
    "    \n",
    "    lower_index = current_clip_index\n",
    "    current_clip_index = len(clips)\n",
    "    \n",
    "    # update metadata\n",
    "    metadata_index = len(metadata_df)\n",
    "    if metadata_df['filename'].str.contains(audio_file).any():\n",
    "        metadata_index = metadata_df[metadata_df['filename'] == audio_file].index[0]\n",
    "    metadata_df.loc[metadata_index, 'filename'] = audio_file\n",
    "    metadata_df.loc[metadata_index, 'sample_rate'] = int(sample_rate)\n",
    "    metadata_df.loc[metadata_index, 'duration'] = audio_duration\n",
    "    metadata_df.loc[metadata_index, 'index_start'] = int(lower_index)\n",
    "    metadata_df.loc[metadata_index, 'index_end'] = int(current_clip_index - 1)\n",
    "    \n",
    "\n",
    "metadata_df = metadata_df.sort_values(by='index_start')\n",
    "\n",
    "metadata_df.to_csv('data/metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Save the clips in the `data/clips/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [00:20<00:00, 23.23it/s]"
     ]
    }
   ],
   "source": [
    "current_index_end = -1\n",
    "\n",
    "pbar = tqdm(total=len(clips))\n",
    "\n",
    "for i, clip in enumerate(clips):\n",
    "    if i > current_index_end:\n",
    "        sub_df = metadata_df[metadata_df['index_end'] > i]\n",
    "        current_index_end = int(sub_df['index_end'].iloc[0])\n",
    "        current_sample_rate = int(sub_df['sample_rate'].iloc[0])\n",
    "    signal_to_mp3(clip, current_sample_rate, 'data/clips_audio/' + str(i) + '.mp3')\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Convert the clips to spectrograms and save them in the `data/spectrograms/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [00:20<00:00, 23.21it/s]\n",
      "100%|██████████| 473/473 [00:59<00:00,  8.16it/s]"
     ]
    }
   ],
   "source": [
    "current_index_end = -1\n",
    "\n",
    "pbar = tqdm(total=len(clips), position=0)\n",
    "\n",
    "for i, clip in enumerate(clips):\n",
    "    if i > current_index_end:\n",
    "        sub_df = metadata_df[metadata_df['index_end'] > i]\n",
    "        current_index_end = int(sub_df['index_end'].iloc[0])\n",
    "        current_sample_rate = int(sub_df['sample_rate'].iloc[0])\n",
    "        current_audio_file = sub_df['filename'].iloc[0]\n",
    "    spectro = signal_to_spectro(clip, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    spectro_to_image(spectro, 'data/clips_spectro_full/' + str(i) + '.png')\n",
    "    mel_spectro = spectro_to_mel_spectro(spectro, current_sample_rate, 256, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    spectro_to_image(mel_spectro, 'data/clips_spectro_256/' + str(i) + '.png')\n",
    "    mel_spectro = spectro_to_mel_spectro(spectro, current_sample_rate, 128, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    spectro_to_image(mel_spectro, 'data/clips_spectro_128/' + str(i) + '.png')\n",
    "    \n",
    "    clips_df.loc[i, 'min_spectro_db'] = spectro.min()\n",
    "    clips_df.loc[i, 'max_spectro_db'] = spectro.max()\n",
    "    clips_df.loc[i, 'filename'] = current_audio_file\n",
    "    pbar.update(1)\n",
    "    \n",
    "clips_df.to_csv('data/clips.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
